---
title: "Assessing the performance of spectre using virtual communities"
author: "Jan Salecker"
date: "8/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assessing the performance of spectre using virtual communities

In this example we want to use the NLMR-virtualspecies approach to assess the performance of spectre udner different parameterisations.

We will vary four parameters:

* landscape size, from 10x10 cells to 30x30 cells
* corr_within, the spatial correlation within species, from 0 to 1
* corr_among, the spatial correlation between species, from 0 to 0.1
* gamma, the maximum number of species, from 100 to 300

For each parameterisation we want to run 5 replicates.
Depending on the parameterisation, calculations may take quite some time. Thus, we will utilize the GWDG HPC to run the simulations.


#### Installation of spectre dev branch on HPC

The following commands can be used to install a specific branch of the spectre package from github.
The github token can be found/created on your github account page.

```{r init, eval=FALSE}
# INSTALL SPECTRE ON HPC:
github_auth_token <- "abc"
remotes::install_github("r-spatialecology/spectre", ref="dev", auth_token = github_auth_token)
```

#### Packages and initialization

Here, we load some packages and define working directories for the hpc, cloudserver and local execution.

```{r packages, eval=FALSE}
library(spectre)
library(tidyverse)
library(future)
library(virtualspecies)
library(furrr)
library(clustermq)
library(landscapetools)

set.seed(3562347)
exec <- "HPC" # "HPC"
dir.hpc <- file.path("/home/uni08/jsaleck/spectre")
dir.cloud <- file.path("/home/jan/netlogo_jan/spectre")
dir.local <- file.path("spectre/vignettes")
```

#### Prepare the parameter matrix

As already described, we want to vary four parameters. In order to run our scenarios in parallel, we create a parameter matrix we can loop through conveniently.
We first define constant parameters. Then we define varying parameters and use the `expand.grid()` function to create a full factorial parameter design matrix.

```{r parameters, eval=FALSE}

## Constant parameters:
replicates <- 1
max_runs <- 20000
energy_threshold <- 0
beta <- 0.75

## Variable parameters:
landscape_size <- c(10,20)
corr_within <- c(0,1)
corr_among <- c(0,0.1)
gamma <- c(100,200)
random_seeds <- round(runif(replicates) * 100000)

## Generate parameter matrix:
parameters <- expand.grid(landscape_size = landscape_size, 
                          corr_within = corr_within,
                          gamma = gamma, 
                          beta = beta,
                          corr_among = corr_among,
                          random_seeds = random_seeds)
``` 

#### Simulation function

In order to send simulations to the HPC, we need a simulation function that takes rows of our parameter matrix as input, then creates the virtual communities, runs the spectre optimization and finally reports some results (including a benchmark).

```{r simfun, eval=FALSE}
simfun <- function(siminputrow, parameters, max_runs, energy_threshold, writeRDS, outdir)
{
  # Read and set parameters
  p <- parameters[siminputrow,]
  set.seed(p$random_seed)
  
  # Construct virtual species:
  spp <- spectre::generate_data_virtualspecies(ncol=p$landscape_size, nrow=p$landscape_size,
                                               corr_within = p$corr_within, 
                                               corr_among = p$corr_among, 
                                               gamma = p$gamma, 
                                               beta = p$beta)
  
  # Calculate alpha:
  alpha <- raster::getValues(sum(spp))
  
  # Construct solution and target:
  solution <- spectre::generate_data_virtualspecies_to_solution(spp)
  target <- spectre:::calculate_solution_commonness_rcpp(solution)
  
  #print("start")
  start_time <- Sys.time()
  res_min_conf <- spectre::run_optimization_min_conf(alpha, p$gamma, target, max_runs, energy_threshold)
  end_time <- Sys.time()
  time_minconf <- as.numeric(end_time - start_time)
 
  # Create tibble
  result <- tibble::tibble(spp.virtual = list(spp),
                           spp.spectre = list(res_min_conf),
                           benchmark = time_minconf)
  
  # Combine with input
  result <- cbind(p, result)
  
  # Write output
  if(isTRUE(writeRDS)) {
    saveRDS(result, file.path(outdir, paste0("spectre_", siminputrow, ".rds")))
  }
  
  return(result)
}
```


#### Execution

Now everything is prepared to run the simulations.
Depending on the parameter `exec` simulations are either performed locally or sent to the HPC via the `Q` function of the clustermq package.

```{r exec, eval=FALSE}
if (exec == "local") {
  plan(multisession)
  results <- furrr::future_map_dfr(seq(nrow(parameters)), function(x) {
    simfun(siminputrow = x, 
           parameters = parameters,
           max_runs = max_runs,
           energy_threshold = energy_threshold,
           writeRDS = FALSE,
           outdir = dir.cloud)
  })
}
if (exec == "HPC") {
  
  maxjobs.hpc <- 2000
  njobs <- min(nrow(parameters), maxjobs.hpc)
  jobIDs <- seq(nrow(parameters))
  
  results <- clustermq::Q(fun = simfun, 
                          siminputrow = jobIDs,
                          const = list(parameters = parameters,
                                       max_runs = max_runs,
                                       energy_threshold = energy_threshold,
                                       writeRDS = TRUE,
                                       outdir = dir.hpc),
                          export = list(), 
                          seed = 42, 
                          n_jobs = njobs, 
                          template = list(job_name = "spectre", # define jobname
                                          log_file = "spectre.log", # define logfile name
                                          queue = "medium",  # define HPC queue
                                          service = "normal", # define HPC service
                                          walltime = "24:00:00", # define walltime
                                          mem_cpu = "4000")) # define memory per cpu   
  results <- dplyr::bind_rows(results)
}
```

#### Store results

After the simlations have finished, we may want to store the final results as rds file.
If the master process "survived", we can simply store the results object.
If the master process crashed, we might want to restore results from the `*.rds` files of each run first.

```{r save, eval=FALSE}
#### Restore results from rds files if neccessary:
results <- purrr::map_dfr(list.files(dir.cloud, pattern = "rds", full.names = TRUE), function(x) {
  res.x <- readRDS(x)
  return(res.x)
})

#### STORE RESULTS:
saveRDS(results, file=file.path(dir.cloud, "virtualspecies_02_advanced_data.rds"))

```

#### Post-processing

Lets first have a look at the energy curves:

```{r plot1}
library(tidyverse)
results <- readRDS("../data/virtualspecies_02_advanced_data.rds")

## PLOT 1: Energy curves
energy <- purrr::map_dfr(1:nrow(results), function(x) {
  energy <- results$spp.spectre[[x]]$energy %>% 
    dplyr::mutate(landscape_size = results$landscape_size[x]) %>% 
    dplyr::mutate(corr_within = results$corr_within[x]) %>% 
    dplyr::mutate(corr_among = results$corr_among[x]) %>%
    dplyr::mutate(gamma = results$gamma[x]) %>% 
    dplyr::mutate(beta = results$beta[x]) %>% 
    dplyr::mutate(random_seeds = results$random_seeds[x])
})
ggplot(energy, aes(x=i, y=energy, group=interaction(corr_within, corr_among))) +
  facet_grid(landscape_size~gamma) +
  geom_line(aes(color=factor(corr_within), lty=factor(corr_among))) +
  ggsci::scale_color_jama() +
  ggthemes::theme_tufte(base_size=12)

ggsave("../figures/virtualspecies_02_advanced_01.png", width=6, height=6, dpi=300)

```

```{r plot2}

## PLOT 2: Minimum energy
energy_min <- energy %>% 
  dplyr::group_by(landscape_size, gamma, corr_within, corr_among, random_seeds) %>% 
  dplyr::summarise(energy = min(energy)) 

energy_min$landscape_size <- factor(energy_min$landscape_size,
                                    levels = unique(energy_min$landscape_size),
                                    labels = paste0(unique(energy_min$landscape_size), "x", unique(energy_min$landscape_size)))
energy_min$gamma <- factor(energy_min$gamma,
                           levels = unique(energy_min$gamma),
                           labels = paste0(unique(energy_min$gamma), " species"))

ggplot(energy_min, aes(x=factor(corr_within), y=factor(corr_among), fill=energy)) +
  facet_grid(landscape_size~gamma) +
  geom_tile() +
  coord_equal() +
  xlab("correlation within species") +
  ylab("correlation among species") +
  scale_fill_viridis_c(direction = -1, option="A") +
  ggthemes::theme_tufte(base_size = 12)
ggsave("../figures/virtualspecies_02_advanced_02.png", width=6, height=6, dpi=300)

```

```{r plot3}

## PLOT 2: Energy improvement
energy_im <- energy %>% 
  dplyr::group_by(landscape_size, gamma, corr_within, corr_among, random_seeds) %>% 
  dplyr::summarise(energy_min = min(energy),
                   energy_max = max(energy)) %>% 
  dplyr::mutate(improvement = ((energy_max - energy_min) / energy_max) * 100)

energy_im$landscape_size <- factor(energy_im$landscape_size,
                                    levels = unique(energy_im$landscape_size),
                                    labels = paste0(unique(energy_im$landscape_size), "x", unique(energy_im$landscape_size)))
energy_im$gamma <- factor(energy_im$gamma,
                           levels = unique(energy_im$gamma),
                           labels = paste0(unique(energy_im$gamma), " species"))

ggplot(energy_im, aes(x=factor(corr_within), y=factor(corr_among), fill=improvement)) +
  facet_grid(landscape_size~gamma) +
  geom_tile() +
  coord_equal() +
  xlab("correlation within species") +
  ylab("correlation among species") +
  scale_fill_viridis_c(direction = 1, option="A") +
  ggthemes::theme_tufte(base_size = 12)
ggsave("../figures/virtualspecies_02_advanced_03.png", width=6, height=6, dpi=300)

```
