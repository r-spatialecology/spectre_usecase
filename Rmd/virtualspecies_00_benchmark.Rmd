---
title: "Virtual species benchmark"
author: "Jan Salecker"
date: "8/31/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Benchmarking the virtualspecies approach on the HPC

Here we want to check how large our landscapes can grow, given the constraints of computing resources at the GWDG HPC.
The main constraint is the walltime, which is 48hrs on the normal queue and 172 hours on the long queue, which is also the absolute maximum of walltime we can get. The only way to extend further would be storing the final result as a intermediate solution and continue optimizing on this solution with a new job.

## Benchmark 01: Sequential execution


```{r run.sequential, eval=FALSE}
library(spectre)
library(tidyverse)
library(future)
library(virtualspecies)
library(furrr)
library(clustermq)
library(landscapetools)

## Source spectre analysis functions (R folder)
sapply(list.files("../R", full.names = TRUE), source)
set.seed(3562347)
exec <- "HPC" # "HPC"
dir.hpc <- file.path("${HOME}/spectre")
dir.cloud <- file.path("${HOME}/spectre/results")

## Constant parameters:
replicates <- 1
max_runs <- 100
energy_threshold <- 0
beta <- 0.75

## Variable parameters:
landscape_size <- c(10, 25, 50, 75, 100)
corr_within <- 0.5
corr_among <- 0.1
gamma <- c(100, 200, 300, 400)
random_seeds <- round(runif(replicates) * 100000)

## Generate parameter matrix:
parameters <- expand.grid(landscape_size = landscape_size, 
                          corr_within = corr_within,
                          gamma = gamma, 
                          beta = beta,
                          corr_among = corr_among,
                          random_seeds = random_seeds)

if (exec == "local") {
  plan(multisession)
  results <- furrr::future_map_dfr(seq(nrow(parameters)), function(x) {
    virtualspecies_simfun(siminputrow = x, 
                          parameters = parameters,
                          max_runs = max_runs,
                          energy_threshold = energy_threshold,
                          writeRDS = FALSE,
                          outdir = dir.cloud)
  })
}
if (exec == "HPC") {
  
  maxjobs.hpc <- 2000
  njobs <- min(nrow(parameters), maxjobs.hpc)
  jobIDs <- seq(nrow(parameters))
  
  results <- clustermq::Q(fun = virtualspecies_simfun, 
                          siminputrow = jobIDs,
                          const = list(parameters = parameters,
                                       max_runs = max_runs,
                                       energy_threshold = energy_threshold,
                                       writeRDS = TRUE,
                                       outdir = dir.hpc),
                          export = list(), 
                          seed = 42, 
                          n_jobs = njobs, 
                          template = list(job_name = "spectre", # define jobname
                                          log_file = "spectre.log", # define logfile name
                                          queue = "medium",  # define HPC queue
                                          service = "normal", # define HPC service
                                          walltime = "48:00:00", # define walltime
                                          mem_cpu = "4000")) # define memory per cpu   
  results <- dplyr::bind_rows(results)
}

#### Restore results from rds files if neccessary:
#results <- purrr::map_dfr(list.files(dir.cloud, pattern = "rds", full.names = TRUE), function(x) {
#  res.x <- readRDS(x)
#  return(res.x)
#})

#### STORE RESULTS:
saveRDS(results, file=file.path(dir.cloud, "data", "virtualspecies_benchmark.rds"))

```

#### Load results

We first need to load the data that was processed by the HPC.

```{r load.data.sequential, include=FALSE}
library(tidyverse)
sapply(list.files("../R", full.names = TRUE), source)
results <- readRDS("../data/virtualspecies_benchmark.rds")
plotdir <- "../figures/virtualspecies_benchmark"
max_runs <- 100
```

#### Time consumption per 100 iterations

```{r t.per.100.sequential}
results %>% 
  dplyr::select(gamma, landscape_size, bench_total) %>% 
  dplyr::mutate(bench_total = as.numeric((bench_total / 60) / 60)) %>% 
  ggplot(., aes(x=gamma, y=bench_total, color=factor(landscape_size), group=landscape_size)) +
  geom_line(size=1) +
  geom_point(size=2) +
  #geom_bar(stat="identity", position="dodge") +
  xlab("Gamma") +
  ylab("Time per 100 iterations [hrs]") +
  #guides(color=guide_legend(title="Landscape size")) +
  ggsci::scale_color_jco() +
  ggthemes::theme_tufte(base_size = 12)

ggsave(filename="benchmark_sequential_100iterations.png", path=plotdir, width=6, height=6, dpi=300)
```

#### Projected time consumption per 50k iterations

```{r t.per.50k.sequential}
## Projected for 50k:
results %>% 
  dplyr::select(gamma, landscape_size, bench_total) %>% 
  dplyr::mutate(bench_total = as.numeric((((bench_total / max_runs) * 50000 )/ 60) / 60)) %>% 
  ggplot(., aes(x=gamma, y=bench_total)) +
  geom_line(size=1, aes(color=factor(landscape_size), group=landscape_size)) +
  geom_point(size=2, aes(color=factor(landscape_size), group=landscape_size)) +
  geom_hline(yintercept = 48, lty=2) +
  geom_label(x=350, y=48, label="48hrs") +
  geom_hline(yintercept = 120, lty=2) +
  geom_label(x=350, y=120, label="120hrs") +
  xlab("Gamma") +
  ylab("Time per 50k iterations [hrs]") +
  guides(color=guide_legend(title="Landscape size")) +
  ggsci::scale_color_jco() +
  ggthemes::theme_tufte(base_size = 12)

ggsave(filename="benchmark_sequential_50kiterations_projected.png", path=plotdir, width=6, height=6, dpi=300)
```

## Benchmark 02: Parallel execution

```{r run.parallel, eval=FALSE}
library(spectre)
library(tidyverse)
library(future)
library(virtualspecies)
library(furrr)
library(clustermq)
library(landscapetools)

## Source spectre analysis functions (R folder)
sapply(list.files("../R", full.names = TRUE), source)
set.seed(3562347)
exec <- "HPC" # "HPC"
dir.hpc <- file.path("/home/uni08/jsaleck/spectre")
dir.cloud <- file.path("/home/jan/netlogo_jan/spectre_usecase")

## Constant parameters:
replicates <- 1
max_runs <- 100
energy_threshold <- 0
beta <- 0.75

## Variable parameters:
landscape_size <- c(10,50,75)
corr_within <- 0.5
corr_among <- 0.1
gamma <- c(100,250,400)
random_seeds <- round(runif(replicates) * 100000)

## Generate parameter matrix:
parameters <- expand.grid(landscape_size = landscape_size, 
                          corr_within = corr_within,
                          gamma = gamma, 
                          beta = beta,
                          corr_among = corr_among,
                          random_seeds = random_seeds)

if (exec == "local") {
  plan(multisession)
  results <- furrr::future_map_dfr(seq(nrow(parameters)), function(x) {
    virtualspecies_simfun(siminputrow = x, 
                          parameters = parameters,
                          max_runs = max_runs,
                          energy_threshold = energy_threshold,
                          writeRDS = FALSE,
                          outdir = dir.cloud)
  })
}
if (exec == "HPC") {
  
  maxjobs.hpc <- 2000
  njobs <- min(nrow(parameters), maxjobs.hpc)
  jobIDs <- seq(nrow(parameters))
  
  results <- clustermq::Q(fun = virtualspecies_simfun, 
                          siminputrow = jobIDs,
                          const = list(parameters = parameters,
                                       max_runs = max_runs,
                                       energy_threshold = energy_threshold,
                                       writeRDS = TRUE,
                                       outdir = dir.hpc),
                          export = list(), 
                          seed = 42, 
                          n_jobs = njobs, 
                          template = list(job_name = "spectre", # define jobname
                                          log_file = "spectre.log", # define logfile name
                                          queue = "medium",  # define HPC queue
                                          service = "normal", # define HPC service
                                          walltime = "04:00:00", # define walltime
                                          n_cpu = "12",
                                          mem_cpu = "4000")) # define memory per cpu   
  results <- dplyr::bind_rows(results)
}

#### Restore results from rds files if neccessary:
#results <- purrr::map_dfr(list.files(dir.cloud, pattern = "rds", full.names = TRUE), function(x) {
#  res.x <- readRDS(x)
#  return(res.x)
#})

#### STORE RESULTS:
saveRDS(results, file=file.path(dir.cloud, "data", "virtualspecies_benchmark_parallel.rds"))


``` 

#### Load results

```{r load.data.parallel, include=FALSE}
library(tidyverse)
sapply(list.files("../R", full.names = TRUE), source)
results <- readRDS("../data/virtualspecies_benchmark_parallel.rds")
plotdir <- "../figures/virtualspecies_benchmark"
max_runs <- 100
```

#### Time consumption per 100 iterations

```{r t.per.100.parallel}
results %>% 
  dplyr::select(gamma, landscape_size, bench_total) %>% 
  dplyr::mutate(bench_total = as.numeric((bench_total / 60) / 60)) %>% 
  ggplot(., aes(x=gamma, y=bench_total, color=factor(landscape_size), group=landscape_size)) +
  geom_line(size=1) +
  geom_point(size=2) +
  #geom_bar(stat="identity", position="dodge") +
  xlab("Gamma") +
  ylab("Time per 100 iterations [hrs]") +
  #guides(color=guide_legend(title="Landscape size")) +
  ggsci::scale_color_jco() +
  ggthemes::theme_tufte(base_size = 12)
ggsave(filename="benchmark_parallel_100iterations.png", path=plotdir, width=6, height=6, dpi=300)
```

#### Projected time consumption per 50k iterations

```{r t.per.50k.parallel}
## Projected for 50k:
results %>% 
  dplyr::select(gamma, landscape_size, bench_total) %>% 
  dplyr::mutate(bench_total = as.numeric((((bench_total / max_runs) * 50000 )/ 60) / 60)) %>% 
  ggplot(., aes(x=gamma, y=bench_total)) +
  geom_line(size=1, aes(color=factor(landscape_size), group=landscape_size)) +
  geom_point(size=2, aes(color=factor(landscape_size), group=landscape_size)) +
  geom_hline(yintercept = 48, lty=2) +
  geom_label(x=350, y=48, label="48hrs") +
  geom_hline(yintercept = 120, lty=2) +
  geom_label(x=350, y=120, label="120hrs") +
  xlab("Gamma") +
  ylab("Time per 50k iterations [hrs]") +
  guides(color=guide_legend(title="Landscape size")) +
  ggsci::scale_color_jco() +
  ggthemes::theme_tufte(base_size = 12)

ggsave(filename="benchmark_parallel_50kiterations_projected.png", path=plotdir, width=6, height=6, dpi=300)
```

## Compare sequential and parallel exeuction

#### Load results

```{r load.data.comparison, include=FALSE}
library(tidyverse)
sapply(list.files("../R", full.names = TRUE), source)
results_singlecore <- readRDS("../data/virtualspecies_benchmark.rds")
results_parallel <- readRDS("../data/virtualspecies_benchmark_parallel.rds")
results_singlecore$job <- "singlecore"
results_parallel$job <- "parallel"
results <- rbind(results_singlecore, results_parallel) %>% 
  dplyr::filter(landscape_size %in% c(10, 50, 75))
plotdir <- "../figures/virtualspecies_benchmark"
max_runs <- 100
```


#### Time consumption per 100 iterations

```{r t.per.100.comparison}
results %>% 
  dplyr::select(job, gamma, landscape_size, bench_total) %>% 
  dplyr::mutate(bench_total = as.numeric((bench_total / 60) / 60)) %>% 
  ggplot(., aes(x=gamma, y=bench_total, color=factor(landscape_size), group=landscape_size)) +
  facet_wrap(~job) +
  geom_line(size=1) +
  geom_point(size=2) +
  #geom_bar(stat="identity", position="dodge") +
  xlab("Gamma") +
  ylab("Time per 100 iterations [hrs]") +
  #guides(color=guide_legend(title="Landscape size")) +
  ggsci::scale_color_jco() +
  ggthemes::theme_tufte(base_size = 12)
ggsave(filename="benchmark_comparison_100iterations.png", path=plotdir, width=6, height=6, dpi=300)
```


#### Projected time consumption per 50k iterations

```{r t.per.50k.comparison}
## Projected for 50k:
results %>% 
  dplyr::select(job, gamma, landscape_size, bench_total) %>% 
  dplyr::mutate(bench_total = as.numeric((((bench_total / max_runs) * 50000 )/ 60) / 60)) %>% 
  ggplot(., aes(x=gamma, y=bench_total)) +
  facet_wrap(~job) +
  geom_line(size=1, aes(color=factor(landscape_size), group=landscape_size)) +
  geom_point(size=2, aes(color=factor(landscape_size), group=landscape_size)) +
  geom_hline(yintercept = 48, lty=2) +
  geom_label(x=350, y=48, label="48hrs") +
  geom_hline(yintercept = 120, lty=2) +
  geom_label(x=350, y=120, label="120hrs") +
  xlab("Gamma") +
  ylab("Time per 50k iterations [hrs]") +
  guides(color=guide_legend(title="Landscape size")) +
  ggsci::scale_color_jco() +
  ggthemes::theme_tufte(base_size = 12)

ggsave(filename="benchmark_comparison_50kiterations_projected.png", path=plotdir, width=6, height=6, dpi=300)
```

## Generalized benchmark plots for manuscript

```{r benchmark.manuscript, include=FALSE}
library(tidyverse)
sapply(list.files("../R", full.names = TRUE), source)
results <- readRDS("../data/virtualspecies_benchmark_parallel.rds")
plotdir <- "../figures/virtualspecies_benchmark"
max_runs <- 100

## Projected for 50k:
plotdata <- results %>% 
  dplyr::select(gamma, landscape_size, bench_total) %>% 
  dplyr::filter(landscape_size != 100) %>% 
  dplyr::mutate(landscape_size = landscape_size * landscape_size) %>% 
  dplyr::mutate(bench_total = as.numeric((((bench_total / max_runs) * 50000 )/ 60) / 60))

gamma.labels <- plotdata %>% 
  dplyr::filter(landscape_size == 5625)


ggplot(plotdata, aes(x=landscape_size, y=bench_total, color=factor(gamma), group=gamma)) +
  geom_line(size=1)  +
  geom_point(size=2) +
  geom_text(data=gamma.labels, size=4, aes(label=paste("γ =", gamma)), nudge_x = -100, nudge_y = 60, family="serif") +
  geom_hline(yintercept = 48, lty=2) +
  geom_label(x=5000, y=48, label="48hrs", color="black", family="serif") +
  geom_hline(yintercept = 480, lty=2) +
  geom_label(x=5000, y=480, label="480hrs", color="black", family="serif") +
  scale_x_continuous(breaks = seq(0,6000,500)) +
  xlab("Landscape size [cells]") +
  ylab("Projected runtime per 50k iterations [hrs]") +
  guides(color="none") +
  ggthemes::scale_color_colorblind() +
  ggthemes::theme_tufte(base_size = 12)

ggsave(filename="benchmark_manuscript.png", path=plotdir, width=6, height=4, dpi=300)
```




